BMW Used Car Price Prediction
This project focuses on predicting the sales price of used BMW cars using a machine learning model and deploying it as a web application with Streamlit.

Project Overview
The core of this project is a machine learning model developed in a Jupyter Notebook, which predicts the price of used BMW cars based on various features. The best performing model, a Gradient Boosting Regressor, is saved for deployment. A Streamlit application is provided to offer a user-friendly interface for making predictions.

Features
Machine Learning Model: A Gradient Boosting Regressor model trained to predict BMW used car prices.

Data Preprocessing: Includes handling of categorical features using one-hot encoding and log-transformation of the target variable (price) for improved model performance.

Model Persistence: The trained model is saved using pickle for easy loading and deployment.

Streamlit Web Application (app.py):

Custom Input Layout: Provides an interactive interface for users to input car features, mirroring the training data's structure.

Denormalization Step: Automatically converts the predicted log-transformed price back to its original currency scale.

User-Friendly Interface: Allows for quick and easy price predictions.

Project Structure
BMW SALES.ipynb: The Jupyter Notebook containing the entire machine learning pipeline, from data loading and exploration to preprocessing, model training, evaluation, and saving the final model.

gradient_boosting_regression_model.pkl: The trained Gradient Boosting Regressor model saved as a pickle file. This file is generated by BMW SALES.ipynb.

app.py: The Python script for the Streamlit web application. It loads the saved model, takes user inputs, preprocesses them, makes a prediction, and displays the denormalized price.

requirements.txt: Lists all the necessary Python libraries required to run the Streamlit application.

Setup and Installation
To set up and run this project locally, follow these steps:

Clone the repository (if applicable) or create project directory:
If you have this project in a Git repository, clone it. Otherwise, create a directory for your project.

Place the files:
Ensure you have the following files in your project directory:

BMW SALES.ipynb (the original notebook)

gradient_boosting_regression_model.pkl (generated from running the notebook)

app.py

requirements.txt

Note: You must run the BMW SALES.ipynb notebook at least once to generate the gradient_boosting_regression_model.pkl file.

Create a virtual environment (recommended):

python -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`

Install dependencies:
Navigate to your project directory in the terminal and install the required libraries:

pip install -r requirements.txt

Usage
Once the setup is complete, you can run the Streamlit web application:

Navigate to the project directory:

cd your_project_directory

Run the Streamlit app:

streamlit run app.py

This command will open the Streamlit application in your default web browser (usually at http://localhost:8501). You can then input the car's details and get an estimated price.

Model Details
The machine learning model utilized is a Gradient Boosting Regressor. Key preprocessing steps from the notebook [cite: uploaded:BMW SALES.ipynb] include:

Log Transformation: The price variable was transformed using np.log() to handle its skewed distribution. The Streamlit app includes a denormalization step using np.exp() to convert the predicted price back to the original scale.

One-Hot Encoding: Categorical features (model, transmission, fuelType) were converted into numerical format using one-hot encoding with pd.get_dummies(drop_first=True).

Important Note on Feature Alignment:
For accurate predictions, the input features provided to the app.py must match the features (and their order, especially for one-hot encoded columns) that the model was trained on. While the app.py attempts to align these columns, it is highly recommended in a production environment to save the exact column names (e.g., X_train.columns.tolist()) from your training dataset and use them explicitly during deployment to ensure consistency.
